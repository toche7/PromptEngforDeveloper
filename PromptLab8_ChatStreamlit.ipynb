{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/toche7/PromptEngforDeveloper/blob/main/PromptLab8_ChatStreamlit.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XLFov09h18yC"
      },
      "source": [
        "# Google CoLab Instructions\n",
        "เอกสารนี้พัฒนามาจากเอกสารของ Jeff Heaton, McKelvey School of Engineering, Washington University in St. Louis\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "ใน Lab นี้ เราจะได้สร้างแอปแชท LLM โดยใช้ StreamLit อย่างเป็นขั้นเป็นตอน เพื่อให้ทุกคนเข้าถึงและทำตามได้ง่าย โดยจะรันแอปนี้ผ่าน Google Colab เพื่อให้ใช้งานได้สะดวกขึ้น อีกทั้งเราจะพาไปรู้จักกับ `llm_util.py` ซึ่งเป็นสคริปต์ยูทิลิตี้ที่ช่วยให้ทำงานกับโมเดลภาษาขนาดใหญ่ (LLMs) ที่รองรับ LangChain ได้ง่ายยิ่งขึ้น ในตัวอย่างนี้ เราจะใช้ LLM ของ Meta เป็นตัวขับเคลื่อนสำหรับแอปแชทของเรา เมื่อจบโมดูลนี้ คุณจะได้แอปแชทที่ใช้งานได้จริง พร้อมความเข้าใจพื้นฐานในการผสาน LLM เข้าไปในโปรเจกต์ต่าง ๆ โดยใช้ StreamLit\n",
        "\n",
        "โค้ดต่อไปนี้เริ่มต้นด้วยการนำเข้าไลบรารี `os` เพื่อจัดการกับระบบไฟล์และตัวแปรสภาพแวดล้อม จากนั้นตรวจสอบว่าโค้ดรันใน Google Colab หรือไม่ โดยพยายามนำเข้าโมดูลจาก `google.colab` ถ้านำเข้าได้ จะตั้งค่าตัวแปร `COLAB` เป็น `True` และพิมพ์ข้อความแจ้งว่ากำลังใช้ Colab แต่ถ้าไม่สามารถนำเข้าได้ จะตั้งค่าเป็น `False` แทน\n",
        "\n",
        "ถ้าอยู่ใน Colab จะตั้งค่าตัวแปรสภาพแวดล้อม `GROQ_API_KEY` จากข้อมูลที่เก็บไว้ใน Colab แล้วติดตั้งไลบรารีที่จำเป็นสำหรับการทำงาน เช่น `langchain`, `langchain_openai`, `openai`, `streamlit`, และ `langchain-groq` ผ่านคำสั่ง pip โดยรวมโค้ดนี้ทำให้สามารถใช้งานได้อย่างเหมาะสมทั้งใน Google Colab และสภาพแวดล้อมอื่น ๆ"
      ],
      "metadata": {
        "id": "L2fUJk5P1gPn"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AWGARRT92DrA",
        "outputId": "28ea9f19-522e-4c14-cb1a-b8a3aabdd982"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Note: using Google CoLab\n",
            "Requirement already satisfied: langchain in /usr/local/lib/python3.10/dist-packages (0.3.4)\n",
            "Collecting langchain_openai\n",
            "  Downloading langchain_openai-0.2.5-py3-none-any.whl.metadata (2.6 kB)\n",
            "Requirement already satisfied: openai in /usr/local/lib/python3.10/dist-packages (1.52.2)\n",
            "Collecting streamlit\n",
            "  Downloading streamlit-1.39.0-py2.py3-none-any.whl.metadata (8.5 kB)\n",
            "Collecting langchain-groq\n",
            "  Downloading langchain_groq-0.2.1-py3-none-any.whl.metadata (2.9 kB)\n",
            "Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.10/dist-packages (from langchain) (6.0.2)\n",
            "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.10/dist-packages (from langchain) (2.0.36)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /usr/local/lib/python3.10/dist-packages (from langchain) (3.10.10)\n",
            "Requirement already satisfied: async-timeout<5.0.0,>=4.0.0 in /usr/local/lib/python3.10/dist-packages (from langchain) (4.0.3)\n",
            "Requirement already satisfied: langchain-core<0.4.0,>=0.3.12 in /usr/local/lib/python3.10/dist-packages (from langchain) (0.3.13)\n",
            "Requirement already satisfied: langchain-text-splitters<0.4.0,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from langchain) (0.3.0)\n",
            "Requirement already satisfied: langsmith<0.2.0,>=0.1.17 in /usr/local/lib/python3.10/dist-packages (from langchain) (0.1.137)\n",
            "Requirement already satisfied: numpy<2,>=1 in /usr/local/lib/python3.10/dist-packages (from langchain) (1.26.4)\n",
            "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in /usr/local/lib/python3.10/dist-packages (from langchain) (2.9.2)\n",
            "Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.10/dist-packages (from langchain) (2.32.3)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<10,>=8.1.0 in /usr/local/lib/python3.10/dist-packages (from langchain) (9.0.0)\n",
            "Collecting langchain-core<0.4.0,>=0.3.12 (from langchain)\n",
            "  Downloading langchain_core-0.3.15-py3-none-any.whl.metadata (6.3 kB)\n",
            "Collecting tiktoken<1,>=0.7 (from langchain_openai)\n",
            "  Downloading tiktoken-0.8.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.6 kB)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.10/dist-packages (from openai) (3.7.1)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.10/dist-packages (from openai) (1.9.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from openai) (0.27.2)\n",
            "Requirement already satisfied: jiter<1,>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from openai) (0.6.1)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from openai) (1.3.1)\n",
            "Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.10/dist-packages (from openai) (4.66.6)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.11 in /usr/local/lib/python3.10/dist-packages (from openai) (4.12.2)\n",
            "Requirement already satisfied: altair<6,>=4.0 in /usr/local/lib/python3.10/dist-packages (from streamlit) (4.2.2)\n",
            "Requirement already satisfied: blinker<2,>=1.0.0 in /usr/lib/python3/dist-packages (from streamlit) (1.4)\n",
            "Requirement already satisfied: cachetools<6,>=4.0 in /usr/local/lib/python3.10/dist-packages (from streamlit) (5.5.0)\n",
            "Requirement already satisfied: click<9,>=7.0 in /usr/local/lib/python3.10/dist-packages (from streamlit) (8.1.7)\n",
            "Requirement already satisfied: packaging<25,>=20 in /usr/local/lib/python3.10/dist-packages (from streamlit) (24.1)\n",
            "Requirement already satisfied: pandas<3,>=1.4.0 in /usr/local/lib/python3.10/dist-packages (from streamlit) (2.2.2)\n",
            "Requirement already satisfied: pillow<11,>=7.1.0 in /usr/local/lib/python3.10/dist-packages (from streamlit) (10.4.0)\n",
            "Requirement already satisfied: protobuf<6,>=3.20 in /usr/local/lib/python3.10/dist-packages (from streamlit) (3.20.3)\n",
            "Requirement already satisfied: pyarrow>=7.0 in /usr/local/lib/python3.10/dist-packages (from streamlit) (17.0.0)\n",
            "Requirement already satisfied: rich<14,>=10.14.0 in /usr/local/lib/python3.10/dist-packages (from streamlit) (13.9.3)\n",
            "Requirement already satisfied: toml<2,>=0.10.1 in /usr/local/lib/python3.10/dist-packages (from streamlit) (0.10.2)\n",
            "Requirement already satisfied: gitpython!=3.1.19,<4,>=3.0.7 in /usr/local/lib/python3.10/dist-packages (from streamlit) (3.1.43)\n",
            "Collecting pydeck<1,>=0.8.0b4 (from streamlit)\n",
            "  Downloading pydeck-0.9.1-py2.py3-none-any.whl.metadata (4.1 kB)\n",
            "Requirement already satisfied: tornado<7,>=6.0.3 in /usr/local/lib/python3.10/dist-packages (from streamlit) (6.3.3)\n",
            "Collecting watchdog<6,>=2.1.5 (from streamlit)\n",
            "  Downloading watchdog-5.0.3-py3-none-manylinux2014_x86_64.whl.metadata (41 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m41.9/41.9 kB\u001b[0m \u001b[31m1.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting groq<1,>=0.4.1 (from langchain-groq)\n",
            "  Downloading groq-0.11.0-py3-none-any.whl.metadata (13 kB)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (2.4.3)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (24.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.5.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (6.1.0)\n",
            "Requirement already satisfied: yarl<2.0,>=1.12.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.17.0)\n",
            "Requirement already satisfied: entrypoints in /usr/local/lib/python3.10/dist-packages (from altair<6,>=4.0->streamlit) (0.4)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from altair<6,>=4.0->streamlit) (3.1.4)\n",
            "Requirement already satisfied: jsonschema>=3.0 in /usr/local/lib/python3.10/dist-packages (from altair<6,>=4.0->streamlit) (4.23.0)\n",
            "Requirement already satisfied: toolz in /usr/local/lib/python3.10/dist-packages (from altair<6,>=4.0->streamlit) (0.12.1)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai) (3.10)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai) (1.2.2)\n",
            "Requirement already satisfied: gitdb<5,>=4.0.1 in /usr/local/lib/python3.10/dist-packages (from gitpython!=3.1.19,<4,>=3.0.7->streamlit) (4.0.11)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->openai) (2024.8.30)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->openai) (1.0.6)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.10/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai) (0.14.0)\n",
            "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.4.0,>=0.3.12->langchain) (1.33)\n",
            "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /usr/local/lib/python3.10/dist-packages (from langsmith<0.2.0,>=0.1.17->langchain) (3.10.10)\n",
            "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from langsmith<0.2.0,>=0.1.17->langchain) (1.0.0)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas<3,>=1.4.0->streamlit) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas<3,>=1.4.0->streamlit) (2024.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas<3,>=1.4.0->streamlit) (2024.2)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.23.4 in /usr/local/lib/python3.10/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain) (2.23.4)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain) (3.4.0)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain) (2.2.3)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich<14,>=10.14.0->streamlit) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich<14,>=10.14.0->streamlit) (2.18.0)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.10/dist-packages (from SQLAlchemy<3,>=1.4->langchain) (3.1.1)\n",
            "Requirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.10/dist-packages (from tiktoken<1,>=0.7->langchain_openai) (2024.9.11)\n",
            "Requirement already satisfied: smmap<6,>=3.0.1 in /usr/local/lib/python3.10/dist-packages (from gitdb<5,>=4.0.1->gitpython!=3.1.19,<4,>=3.0.7->streamlit) (5.0.1)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->altair<6,>=4.0->streamlit) (3.0.2)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.10/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.4.0,>=0.3.12->langchain) (3.0.0)\n",
            "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (2024.10.1)\n",
            "Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (0.35.1)\n",
            "Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (0.20.0)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich<14,>=10.14.0->streamlit) (0.1.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas<3,>=1.4.0->streamlit) (1.16.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from yarl<2.0,>=1.12.0->aiohttp<4.0.0,>=3.8.3->langchain) (0.2.0)\n",
            "Downloading langchain_openai-0.2.5-py3-none-any.whl (50 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.4/50.4 kB\u001b[0m \u001b[31m987.0 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading streamlit-1.39.0-py2.py3-none-any.whl (8.7 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m8.7/8.7 MB\u001b[0m \u001b[31m19.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading langchain_groq-0.2.1-py3-none-any.whl (14 kB)\n",
            "Downloading groq-0.11.0-py3-none-any.whl (106 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m106.5/106.5 kB\u001b[0m \u001b[31m4.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading langchain_core-0.3.15-py3-none-any.whl (408 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m408.7/408.7 kB\u001b[0m \u001b[31m9.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pydeck-0.9.1-py2.py3-none-any.whl (6.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.9/6.9 MB\u001b[0m \u001b[31m32.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading tiktoken-0.8.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m36.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading watchdog-5.0.3-py3-none-manylinux2014_x86_64.whl (79 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m79.3/79.3 kB\u001b[0m \u001b[31m2.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: watchdog, tiktoken, pydeck, groq, langchain-core, streamlit, langchain_openai, langchain-groq\n",
            "  Attempting uninstall: langchain-core\n",
            "    Found existing installation: langchain-core 0.3.13\n",
            "    Uninstalling langchain-core-0.3.13:\n",
            "      Successfully uninstalled langchain-core-0.3.13\n",
            "Successfully installed groq-0.11.0 langchain-core-0.3.15 langchain-groq-0.2.1 langchain_openai-0.2.5 pydeck-0.9.1 streamlit-1.39.0 tiktoken-0.8.0 watchdog-5.0.3\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "\n",
        "try:\n",
        "    from google.colab import drive, userdata\n",
        "    COLAB = True\n",
        "    print(\"Note: using Google CoLab\")\n",
        "except:\n",
        "    print(\"Note: not using Google CoLab\")\n",
        "    COLAB = False\n",
        "\n",
        "# Groq Secrets\n",
        "if COLAB:\n",
        "    os.environ[\"GROQ_API_KEY\"] = userdata.get('GROQ_API_KEY')\n",
        "\n",
        "# Install needed libraries in CoLab\n",
        "if COLAB:\n",
        "    !pip install langchain langchain_openai openai streamlit langchain-groq"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v2MPPX0c1pHi"
      },
      "source": [
        "# Creating a Chat Application\n",
        "\n",
        "เราจะสร้างไฟล์ดังนี้:\n",
        "\n",
        "* **app.py** - แอปพลิเคชันหลักของ StreamLit สำหรับแชท\n",
        "\n",
        "\n",
        "## Chat Application\n",
        "โค้ดนี้สร้างแอปพลิเคชันแชทบอทโดยใช้ Streamlit และโมเดลภาษาจาก `ChatGroq` ในไลบรารี LangChain โดยการตั้งค่าเริ่มต้นและรูปแบบการทำงานจะอยู่ในไฟล์ชื่อ `app.py` โดยโค้ดมีรายละเอียดดังนี้:\n",
        "\n",
        "1. **การนำเข้าโมดูล**:\n",
        "   - นำเข้า `ChatGroq` จาก `langchain_groq` สำหรับการทำงานกับโมเดลภาษา\n",
        "   - นำเข้า Streamlit (`st`) เพื่อสร้างอินเทอร์เฟซผู้ใช้\n",
        "   - นำเข้า `ConversationSummaryMemory`, `PromptTemplate`, และ `ConversationChain` จาก LangChain ซึ่งใช้สำหรับจัดการหน่วยความจำ, การสร้างเทมเพลตคำถาม, และจัดการการสนทนา\n",
        "\n",
        "2. **การตั้งค่าโมเดลภาษา (LLM)**:\n",
        "   - โค้ดกำหนดตัวแปร `llm` เป็นอินสแตนซ์ของ `ChatGroq` และระบุโมเดลภาษาที่จะใช้คือ `\"gemma2-9b-it\"`\n",
        "\n",
        "3. **ฟังก์ชัน `create_chatbot`**:\n",
        "   - ฟังก์ชันนี้ใช้สร้างแชทบอทที่มีหน่วยความจำ (`ConversationSummaryMemory`) ซึ่งช่วยให้แชทบอทสามารถติดตามบริบทของการสนทนา\n",
        "   - มีการกำหนด `template` สำหรับแชทบอท ซึ่งเริ่มต้นด้วยข้อความของระบบว่า “System: You are a helpful assistant. Answer questions clearly and concisely.” เพื่อให้แชทบอททำงานตามบทบาทที่กำหนดไว้\n",
        "   - ตัวเทมเพลตประกอบด้วย `{history}` สำหรับประวัติการสนทนาและ `{input}` สำหรับข้อความที่ผู้ใช้ป้อน จากนั้นคืนค่าเป็น `ConversationChain` ที่ประกอบไปด้วยโมเดลภาษา, เทมเพลต, และหน่วยความจำ เพื่อให้แชทบอทสามารถใช้ข้อมูลบริบทจากการสนทนาเดิมได้\n",
        "\n",
        "4. **การตั้งค่า Streamlit**:\n",
        "   - แสดงหัวข้อแอปเป็น \"Chat\" โดยใช้ `st.title(\"Chat\")`\n",
        "   - เช็คว่าใน `st.session_state` มีอินสแตนซ์ของแชทบอทหรือยัง ถ้ายังไม่มี จะสร้างแชทบอทใหม่โดยเรียก `create_chatbot`\n",
        "   - เช็คสถานะของ `st.session_state.messages` เพื่อเก็บประวัติการสนทนา ถ้ายังไม่มีจะสร้างเป็นลิสต์ว่าง ๆ\n",
        "\n",
        "5. **การแสดงประวัติการสนทนา**:\n",
        "   - ลูปผ่าน `st.session_state.messages` และแสดงข้อความจากผู้ใช้และแชทบอททีละข้อความบนหน้าจอแชท\n",
        "\n",
        "6. **การรับข้อความจากผู้ใช้และตอบกลับ**:\n",
        "   - เมื่อผู้ใช้กรอกข้อความในช่องอินพุต ข้อความนั้นจะถูกเพิ่มเข้าในประวัติการสนทนาและแสดงในอินเทอร์เฟซ\n",
        "   - แชทบอทประมวลผลข้อความที่ได้รับโดยใช้ฟังก์ชัน `predict` ของ `ConversationChain` และสร้างข้อความตอบกลับ จากนั้นแสดงในส่วนของผู้ช่วยและบันทึกลงในประวัติการสนทนา\n",
        "\n",
        "โดยรวม โค้ดนี้สร้างแอปพลิเคชันแชทบอทที่มีระบบหน่วยความจำและบริบทเพื่อให้การสนทนาสอดคล้องและต่อเนื่อง\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nEQ9c5Akqj_R",
        "outputId": "2d923b13-2544-47f5-faf7-57d855aee5d8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing app.py\n"
          ]
        }
      ],
      "source": [
        "%%writefile app.py\n",
        "from langchain_groq import ChatGroq\n",
        "import streamlit as st\n",
        "from langchain.memory import ConversationSummaryMemory\n",
        "from langchain.prompts.prompt import PromptTemplate\n",
        "from langchain.chains import ConversationChain\n",
        "import sys\n",
        "\n",
        "llm = ChatGroq(\n",
        "    model=\"gemma2-9b-it\",\n",
        ")\n",
        "\n",
        "def create_chatbot(llm):\n",
        "    memory = ConversationSummaryMemory(llm=llm)\n",
        "\n",
        "    # Define the system prompt directly in the template\n",
        "    template = \"\"\"System: You are a helpful assistant. Answer questions clearly and concisely.\n",
        "\n",
        "{history}\n",
        "User: {input}\n",
        "\n",
        "Assistant:\n",
        "\"\"\"\n",
        "    PROMPT = PromptTemplate(input_variables=[\"history\", \"input\"], template=template)\n",
        "    return ConversationChain(llm=llm, prompt=PROMPT, memory=memory, verbose=False)\n",
        "\n",
        "\n",
        "st.title(\"Chat\")\n",
        "\n",
        "# Initialize the chat and messages\n",
        "if \"chat\" not in st.session_state:\n",
        "    st.session_state.chat = create_chatbot(llm)\n",
        "\n",
        "if \"messages\" not in st.session_state:\n",
        "    st.session_state.messages = []\n",
        "\n",
        "# Display the conversation history\n",
        "for message in st.session_state.messages:\n",
        "    with st.chat_message(message[\"role\"]):\n",
        "        st.markdown(\n",
        "            message[\"content\"],\n",
        "        )\n",
        "\n",
        "# Process user input and chatbot response\n",
        "if prompt := st.chat_input(\"What is up?\"):\n",
        "    st.session_state.messages.append({\"role\": \"user\", \"content\": prompt})\n",
        "    with st.chat_message(\"user\"):\n",
        "        st.markdown(\n",
        "            prompt,\n",
        "        )\n",
        "\n",
        "    with st.chat_message(\"assistant\"):\n",
        "        response = st.session_state.chat.predict(input=prompt)\n",
        "        st.markdown(\n",
        "            response,\n",
        "        )\n",
        "    st.session_state.messages.append({\"role\": \"assistant\", \"content\": response})\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eMqVgvmxhySA"
      },
      "source": [
        "เราต้องไปเอา password จากการใช้ lib localtunnel เพื่อการเข้าถึงการใช้งาน server จากภายนอกเพื่อทำให้ run Streamlit ใน Colab ได้  \n",
        "\n",
        "ตัวเลข IP ที่ได้นี้จะเป็น password ที่เราจะนำไปใช้ใน step ต่อไป"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0iJmAPR8c-JE",
        "outputId": "5a890779-8d16-4afd-a4d8-e96943149958"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "34.70.193.156"
          ]
        }
      ],
      "source": [
        "!curl https://loca.lt/mytunnelpassword"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H3lKrMcvh3_F"
      },
      "source": [
        "We launch the StreamLit server and obtain its URL. You will need the above password when you access the URL it gives you.\n",
        "\n",
        "เราจะทำการขึ้น StreamLit Server และได้ URL ของมัน กดไปที่ link ที่ได้จากการ run คำสั่งด้านล่างนี้"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YSLPrByztQOe",
        "outputId": "e7d66024-742a-484a-a95a-a15755d27f08"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l(\u001b[100;90m⠂⠂⠂⠂⠂⠂⠂⠂⠂⠂⠂⠂⠂⠂⠂⠂⠂⠂\u001b[0m) ⠏ idealTree:75ac80b86e83d4a2: \u001b[7msill\u001b[0m \u001b[35midealTree\u001b[0m buildDeps\u001b[0m\u001b[K\r(\u001b[100;90m⠂⠂⠂⠂⠂⠂⠂⠂⠂⠂⠂⠂⠂⠂⠂⠂⠂⠂\u001b[0m) ⠏ idealTree:75ac80b86e83d4a2: \u001b[7msill\u001b[0m \u001b[35midealTree\u001b[0m buildDeps\u001b[0m\u001b[K\r(\u001b[100;90m⠂⠂⠂⠂⠂⠂⠂⠂⠂⠂⠂⠂⠂⠂⠂⠂⠂⠂\u001b[0m) ⠙ idealTree:75ac80b86e83d4a2: \u001b[7msill\u001b[0m \u001b[35midealTree\u001b[0m buildDeps\u001b[0m\u001b[K\r(\u001b[107;97m#########\u001b[0m\u001b[100;90m⠂⠂⠂⠂⠂⠂⠂⠂⠂\u001b[0m) ⠧ idealTree:75ac80b86e83d4a2: \u001b[32;40mtiming\u001b[0m \u001b[35midealTree:#root\u001b[0m Compl\u001b[0m\u001b[K\r(\u001b[107;97m#########\u001b[0m\u001b[100;90m⠂⠂⠂⠂⠂⠂⠂⠂⠂\u001b[0m) ⠧ idealTree:75ac80b86e83d4a2: \u001b[32;40mtiming\u001b[0m \u001b[35midealTree:#root\u001b[0m Compl\u001b[0m\u001b[K\r(\u001b[107;97m#########\u001b[0m\u001b[100;90m⠂⠂⠂⠂⠂⠂⠂⠂⠂\u001b[0m) ⠙ idealTree:75ac80b86e83d4a2: \u001b[32;40mtiming\u001b[0m \u001b[35midealTree:#root\u001b[0m Compl\u001b[0m\u001b[K\r(\u001b[107;97m#########\u001b[0m\u001b[100;90m⠂⠂⠂⠂⠂⠂⠂⠂⠂\u001b[0m) ⠦ idealTree:75ac80b86e83d4a2: \u001b[32;40mtiming\u001b[0m \u001b[35midealTree:#root\u001b[0m Compl\u001b[0m\u001b[K\r(\u001b[107;97m#########\u001b[0m\u001b[100;90m⠂⠂⠂⠂⠂⠂⠂⠂⠂\u001b[0m) ⠦ idealTree:75ac80b86e83d4a2: \u001b[32;40mtiming\u001b[0m \u001b[35midealTree:#root\u001b[0m Compl\u001b[0m\u001b[K\r(\u001b[107;97m#########\u001b[0m\u001b[100;90m⠂⠂⠂⠂⠂⠂⠂⠂⠂\u001b[0m) ⠦ idealTree:75ac80b86e83d4a2: \u001b[32;40mtiming\u001b[0m \u001b[35midealTree:#root\u001b[0m Compl\u001b[0m\u001b[K\r(\u001b[107;97m#########\u001b[0m\u001b[100;90m⠂⠂⠂⠂⠂⠂⠂⠂⠂\u001b[0m) ⠹ idealTree:75ac80b86e83d4a2: \u001b[32;40mtiming\u001b[0m \u001b[35midealTree:#root\u001b[0m Compl\u001b[0m\u001b[K\r(\u001b[107;97m#########\u001b[0m\u001b[100;90m⠂⠂⠂⠂⠂⠂⠂⠂⠂\u001b[0m) ⠹ idealTree:75ac80b86e83d4a2: \u001b[32;40mtiming\u001b[0m \u001b[35midealTree:#root\u001b[0m Compl\u001b[0m\u001b[K\r(\u001b[107;97m#########\u001b[0m\u001b[100;90m⠂⠂⠂⠂⠂⠂⠂⠂⠂\u001b[0m) ⠦ idealTree:75ac80b86e83d4a2: \u001b[32;40mtiming\u001b[0m \u001b[35midealTree:#root\u001b[0m Compl\u001b[0m\u001b[K\r(\u001b[107;97m#########\u001b[0m\u001b[100;90m⠂⠂⠂⠂⠂⠂⠂⠂⠂\u001b[0m) ⠸ reify:localtunnel: \u001b[7msill\u001b[0m \u001b[35maudit\u001b[0m bulk request {\u001b[0m\u001b[K\r(\u001b[107;97m#########\u001b[0m\u001b[100;90m⠂⠂⠂⠂⠂⠂⠂⠂⠂\u001b[0m) ⠋ reify:localtunnel: \u001b[7msill\u001b[0m \u001b[35maudit\u001b[0m bulk request {\u001b[0m\u001b[K\r(\u001b[107;97m#########\u001b[0m\u001b[100;90m⠂⠂⠂⠂⠂⠂⠂⠂⠂\u001b[0m) ⠴ reify:localtunnel: \u001b[7msill\u001b[0m \u001b[35maudit\u001b[0m bulk request {\u001b[0m\u001b[K\r(\u001b[107;97m#########\u001b[0m\u001b[100;90m⠂⠂⠂⠂⠂⠂⠂⠂⠂\u001b[0m) ⠙ reify:localtunnel: \u001b[7msill\u001b[0m \u001b[35maudit\u001b[0m bulk request {\u001b[0m\u001b[K\r(\u001b[107;97m#########\u001b[0m\u001b[100;90m⠂⠂⠂⠂⠂⠂⠂⠂⠂\u001b[0m) ⠙ reify:localtunnel: \u001b[7msill\u001b[0m \u001b[35maudit\u001b[0m bulk request {\u001b[0m\u001b[K\r(\u001b[107;97m#########\u001b[0m\u001b[100;90m⠂⠂⠂⠂⠂⠂⠂⠂⠂\u001b[0m) ⠙ reify:localtunnel: \u001b[7msill\u001b[0m \u001b[35maudit\u001b[0m bulk request {\u001b[0m\u001b[K\r(\u001b[107;97m#########\u001b[0m\u001b[100;90m⠂⠂⠂⠂⠂⠂⠂⠂⠂\u001b[0m) ⠙ reify:localtunnel: \u001b[7msill\u001b[0m \u001b[35maudit\u001b[0m bulk request {\u001b[0m\u001b[K\r(\u001b[107;97m##########\u001b[0m\u001b[100;90m⠂⠂⠂⠂⠂⠂⠂⠂\u001b[0m) ⠹ reify:get-caller-file: \u001b[32;40mhttp\u001b[0m \u001b[35mfetch\u001b[0m GET 200 https://regist\u001b[0m\u001b[K\r(\u001b[107;97m#################\u001b[0m\u001b[100;90m⠂\u001b[0m) ⠇ reify:y18n: \u001b[32;40mhttp\u001b[0m \u001b[35mfetch\u001b[0m GET 200 https://registry.npmjs.or\u001b[0m\u001b[K\r(\u001b[107;97m##################\u001b[0m) ⠹ reify:yargs: \u001b[32;40mhttp\u001b[0m \u001b[35mfetch\u001b[0m GET 200 https://registry.npmjs.o\u001b[0m\u001b[K\r\r\u001b[K\u001b[?25hyour url is: https://yummy-candles-fix.loca.lt\n",
            "^C\n"
          ]
        }
      ],
      "source": [
        "!streamlit run app.py &>/content/logs.txt &\n",
        "!npx --yes localtunnel --port 8501"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "คำสั่งนี้เป็นการใช้ใน Google Colab เพื่อรันแอปพลิเคชัน Streamlit และเชื่อมต่อกับ LocalTunnel ดังนี้:\n",
        "\n",
        "1. **รันแอป Streamlit**:\n",
        "   - `!streamlit run app.py &>/content/logs.txt &`\n",
        "   - คำสั่งนี้จะรันไฟล์ Python ที่ชื่อ `app.py` โดยใช้ Streamlit\n",
        "   - `&>` ใช้เพื่อส่งออกผลลัพธ์ทั้ง stdout และ stderr ไปยังไฟล์ `logs.txt` ในโฟลเดอร์ `/content`\n",
        "   - `&` ที่ท้ายคำสั่งหมายความว่าการรันจะเกิดขึ้นในพื้นหลัง (background) ทำให้คุณสามารถรันคำสั่งถัดไปได้โดยไม่ต้องรอให้ Streamlit เสร็จสิ้น\n",
        "\n",
        "2. **เชื่อมต่อกับ LocalTunnel**:\n",
        "   - `!npx --yes localtunnel --port 8501`\n",
        "   - คำสั่งนี้จะใช้ `npx` เพื่อเรียกใช้งาน LocalTunnel ซึ่งจะทำการสร้าง URL สาธารณะเพื่อเข้าถึงแอป Streamlit ที่รันอยู่ที่พอร์ต 8501\n",
        "   - `--yes` จะยืนยันการติดตั้งแพ็คเกจที่จำเป็น\n",
        "\n"
      ],
      "metadata": {
        "id": "I2oL6qr66LVA"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rUH52Q_wknk0"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "anaconda-cloud": {},
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.4"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}